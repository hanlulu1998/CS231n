# 斯坦福大学CS231n2016年冬季课程作业

***所有课程初始代码下载地址http://cs231n.stanford.edu/assignments/***

[toc]



## 课程作业1

### Q1：k-最近邻分类器（20分）

IPython Notebook文件**knn.ipynb**将会带你实现kNN分类器。

### Q2：训练一个SVM（25分）

IPython Notebook文件**svm.ipynb**将带你实现SVM分类器。

### Q3：实现Softmax分类器（20分）

IPython Notebook文件**softmax.ipynb**将带你实现softmax分类器。

### Q4：实现2层神经网络（25分）

IPython Notebook文件**two_layer_net.ipynb**带你实现一个2层神经网络。

### Q5：更高层次表达：图像特征（10分）

IPython Notebook文件**features.ipynb**带你比较使用更高层次表达相较于使用原始像素对于算法性能的提升。

### Q6：加分：做点儿其他的！（+10分）

实现、调查或者分析其他一些与本次作业相关的主题，并使用你实现的代码。例如，有没有什么你们可以问的有趣问题？能不能做出一些具有洞察力的图表？或者任何有趣且值得一看的东西？也许你还可以对损失函数做点其他实验？如果你尝试了一些够酷东西，我们将给你10分的加分，这将影响你的课程表现。

## 课程作业2

### Q1：全连接神经网络（30分）

IPython Notebook文件**FullyConnectedNets.ipynb**将会向你介绍我们的模块化设计，然后使用不同的层来构建任意深度的全连接网络。为了对模型进行最优化，还需要实现几个常用的更新方法。

### Q2：批量归一化（30分）

在IPython Notebook文件**BatchNormalization.ipynb**中，你需要实现批量归一化，然后将其应用于深度全连接网络的训练中。

### Q3：随机失活（Dropout）（10分）

IPython Notebook文件**Dropout.ipynb**将会帮助你需要实现随机失活，然后在模型泛化中检查它的效果。

### Q4：在CIFAR-10上运行卷积神经网络（30分）

在IPython Notebook文件**ConvolutionalNetworks.ipynb**中，你将实现几个卷积神经网络中常用的新的层。你将在CIFAR-10上训练一个深度较浅的卷积神经网络，然后由你决定竭尽所能地训练处一个最好网络。

### Q5：做点儿其他的！（+10分） 

在训练网络的过程中，为了得到更好的结果，你可以自由实现任何想法。你可以修改训练器（solver），实现额外的层，使用不同的正则化方法，使用模型集成，或者任何其它你想到的东西。如果你实现了作业要求以外的内容，那么将得到加分。

### Q6: Pytorch/TensorFlow入门（编者后添加）

从2017版本后作业2中添加了TensorFlow.ipynb和PyTorch.ipynb作为神经网络框架入门学习，这里提供了2019版本附带的两个文件，原因是2019版本使用的框架版本更新，同时指导更加完善，更易入门。可以选择自己想要的版本学习。



